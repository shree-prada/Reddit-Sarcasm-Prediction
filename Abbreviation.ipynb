{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3622269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important imports to be added\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c0e58f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bhavn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#downloading stopwords library from nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee471aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading csv and filling out missing values\n",
    "df = pd.read_csv('Documents\\\\train-balanced-sarcasm.csv')\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb9fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking only necessary comments\n",
    "df = df[['label','comment','author','score','created_utc','parent_comment']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d11e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>-4</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>-8</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  score   \n",
       "0      0                                         NC and NH.  Trumpbart      2  \\\n",
       "1      0  You do know west teams play against west teams...  Shbshb906     -4   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth      3   \n",
       "3      0  This meme isn't funny none of the \"new york ni...  icebrotha     -8   \n",
       "4      0                    I could use one of those tools.  cush2push      6   \n",
       "\n",
       "           created_utc                                     parent_comment  \n",
       "0  2016-10-16 23:55:23  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  2016-11-01 00:24:10  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2  2016-09-22 21:45:37                            They're favored to win.  \n",
       "3  2016-10-18 21:03:47                         deadass don't kill my buzz  \n",
       "4  2016-12-30 17:00:13  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdba0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a string contains emojis\n",
    "def has_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               u\"\\U000024C2-\\U0001F251\" \n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return bool(emoji_pattern.search(text))\n",
    " \n",
    "# Function to replace emojis with their meanings\n",
    "def replace_emojis(text):\n",
    "    return emoji.demojize(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a268f823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swifter in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\bhavn\\appdata\\roaming\\python\\python311\\site-packages (from swifter) (2.0.1)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from swifter) (5.9.0)\n",
      "Requirement already satisfied: dask[dataframe]>=2.10.0 in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from swifter) (2023.6.0)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in c:\\users\\bhavn\\appdata\\roaming\\python\\python311\\site-packages (from swifter) (4.65.0)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\bhavn\\appdata\\roaming\\python\\python311\\site-packages (from dask[dataframe]>=2.10.0->swifter) (8.1.4)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2023.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (23.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\bhavn\\appdata\\roaming\\python\\python311\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bhavn\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bhavn\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.0.0->swifter) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\bhavn\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.0.0->swifter) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhavn\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.33.0->swifter) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.13.0->dask[dataframe]>=2.10.0->swifter) (3.11.0)\n",
      "Requirement already satisfied: locket in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (from partd>=1.2.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bhavn\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791b46e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\bhavn\\anaconda3\\lib\\site-packages (2.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807b2911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bhavn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import swifter\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "#removing some important stopwords for sarcasm detection\n",
    "stops = set(stopwords.words('english')) - {'no','not','nor','against','above','below','off','own'}\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_text(comment):\n",
    "    #cleaning the text by removing links, usernames,HTML Tags,expansion of words,username removal,etc.\n",
    "    text = str(comment)\n",
    "    # Check for emojis\n",
    "    has_emojis = has_emoji(text)\n",
    "    # Replace emojis with meanings\n",
    "    text = replace_emojis(text)\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',' ',text)\n",
    "    text = re.sub(\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"[0-9]+\",\" \",text)\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\",\" \",text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"n\\'t\", ' not',text)\n",
    "    text = text.replace('\\\\r', ' ')\n",
    "    text = text.replace('\\\\\"', ' ')\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    text = re.sub('[^A-Za-z0-9]+',' ', text)\n",
    "    #tokenization\n",
    "    tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stops]\n",
    "    #lemmatization\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    text = ' '.join(lemmatized_tokens)\n",
    "    text = text.lower().strip()\n",
    "    return text, has_emojis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a045667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f987043f0243fbba971b1b1b4681f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1010826 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply text cleaning and emoji replacement\n",
    "df[\"cleaned_comment\"], df[\"has_emoji\"] = zip(*df.swifter.apply(lambda x: clean_text(x[\"comment\"]), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54add7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>has_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "      <td>nc nh</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>-4</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "      <td>know west team play against west team east tea...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "      <td>underdog earlier today since gronk announcemen...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>-8</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "      <td>meme not funny none new york nigga one</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "      <td>could use one tool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010821</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm sure that Iran and N. Korea have the techn...</td>\n",
       "      <td>TwarkMain</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-04-25 00:47:52</td>\n",
       "      <td>No one is calling this an engineered pathogen,...</td>\n",
       "      <td>sure iran n korea technology create pig bird h...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010822</th>\n",
       "      <td>1</td>\n",
       "      <td>whatever you do, don't vote green!</td>\n",
       "      <td>BCHarvey</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-05-14 22:27:40</td>\n",
       "      <td>In a move typical of their recent do-nothing a...</td>\n",
       "      <td>whatever not vote green</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010823</th>\n",
       "      <td>1</td>\n",
       "      <td>Perhaps this is an atheist conspiracy to make ...</td>\n",
       "      <td>rebelcommander</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-11 00:22:57</td>\n",
       "      <td>Screw the Disabled--I've got to get to Church ...</td>\n",
       "      <td>perhaps atheist conspiracy make christian look...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010824</th>\n",
       "      <td>1</td>\n",
       "      <td>The Slavs got their own country - it is called...</td>\n",
       "      <td>catsi</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-23 21:12:49</td>\n",
       "      <td>I've always been unsettled by that. I hear a l...</td>\n",
       "      <td>slav got own country called kosovo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010825</th>\n",
       "      <td>1</td>\n",
       "      <td>values, as in capitalism .. there is good mone...</td>\n",
       "      <td>frogking</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-24 06:20:14</td>\n",
       "      <td>Why do the people who make our laws seem unabl...</td>\n",
       "      <td>value capitalism good money imprisoning people</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010826 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            comment   \n",
       "0            0                                         NC and NH.  \\\n",
       "1            0  You do know west teams play against west teams...   \n",
       "2            0  They were underdogs earlier today, but since G...   \n",
       "3            0  This meme isn't funny none of the \"new york ni...   \n",
       "4            0                    I could use one of those tools.   \n",
       "...        ...                                                ...   \n",
       "1010821      1  I'm sure that Iran and N. Korea have the techn...   \n",
       "1010822      1                 whatever you do, don't vote green!   \n",
       "1010823      1  Perhaps this is an atheist conspiracy to make ...   \n",
       "1010824      1  The Slavs got their own country - it is called...   \n",
       "1010825      1  values, as in capitalism .. there is good mone...   \n",
       "\n",
       "                 author  score          created_utc   \n",
       "0             Trumpbart      2  2016-10-16 23:55:23  \\\n",
       "1             Shbshb906     -4  2016-11-01 00:24:10   \n",
       "2              Creepeth      3  2016-09-22 21:45:37   \n",
       "3             icebrotha     -8  2016-10-18 21:03:47   \n",
       "4             cush2push      6  2016-12-30 17:00:13   \n",
       "...                 ...    ...                  ...   \n",
       "1010821       TwarkMain      2  2009-04-25 00:47:52   \n",
       "1010822        BCHarvey      1  2009-05-14 22:27:40   \n",
       "1010823  rebelcommander      1  2009-01-11 00:22:57   \n",
       "1010824           catsi      1  2009-01-23 21:12:49   \n",
       "1010825        frogking      2  2009-01-24 06:20:14   \n",
       "\n",
       "                                            parent_comment   \n",
       "0        Yeah, I get that argument. At this point, I'd ...  \\\n",
       "1        The blazers and Mavericks (The wests 5 and 6 s...   \n",
       "2                                  They're favored to win.   \n",
       "3                               deadass don't kill my buzz   \n",
       "4        Yep can confirm I saw the tool they use for th...   \n",
       "...                                                    ...   \n",
       "1010821  No one is calling this an engineered pathogen,...   \n",
       "1010822  In a move typical of their recent do-nothing a...   \n",
       "1010823  Screw the Disabled--I've got to get to Church ...   \n",
       "1010824  I've always been unsettled by that. I hear a l...   \n",
       "1010825  Why do the people who make our laws seem unabl...   \n",
       "\n",
       "                                           cleaned_comment  has_emoji  \n",
       "0                                                    nc nh      False  \n",
       "1        know west team play against west team east tea...      False  \n",
       "2        underdog earlier today since gronk announcemen...      False  \n",
       "3                   meme not funny none new york nigga one      False  \n",
       "4                                       could use one tool      False  \n",
       "...                                                    ...        ...  \n",
       "1010821  sure iran n korea technology create pig bird h...      False  \n",
       "1010822                            whatever not vote green      False  \n",
       "1010823  perhaps atheist conspiracy make christian look...      False  \n",
       "1010824                 slav got own country called kosovo      False  \n",
       "1010825     value capitalism good money imprisoning people      False  \n",
       "\n",
       "[1010826 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c9efb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010826"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['has_emoji'].value_counts()[False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5fe1509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "         label                                            comment   \n",
      "0            0                                         NC and NH.  \\\n",
      "1            0  You do know west teams play against west teams...   \n",
      "2            0  They were underdogs earlier today, but since G...   \n",
      "3            0  This meme isn't funny none of the \"new york ni...   \n",
      "4            0                    I could use one of those tools.   \n",
      "...        ...                                                ...   \n",
      "1010821      1  I'm sure that Iran and N. Korea have the techn...   \n",
      "1010822      1                 whatever you do, don't vote green!   \n",
      "1010823      1  Perhaps this is an atheist conspiracy to make ...   \n",
      "1010824      1  The Slavs got their own country - it is called...   \n",
      "1010825      1  values, as in capitalism .. there is good mone...   \n",
      "\n",
      "                 author  score          created_utc   \n",
      "0             Trumpbart      2  2016-10-16 23:55:23  \\\n",
      "1             Shbshb906     -4  2016-11-01 00:24:10   \n",
      "2              Creepeth      3  2016-09-22 21:45:37   \n",
      "3             icebrotha     -8  2016-10-18 21:03:47   \n",
      "4             cush2push      6  2016-12-30 17:00:13   \n",
      "...                 ...    ...                  ...   \n",
      "1010821       TwarkMain      2  2009-04-25 00:47:52   \n",
      "1010822        BCHarvey      1  2009-05-14 22:27:40   \n",
      "1010823  rebelcommander      1  2009-01-11 00:22:57   \n",
      "1010824           catsi      1  2009-01-23 21:12:49   \n",
      "1010825        frogking      2  2009-01-24 06:20:14   \n",
      "\n",
      "                                            parent_comment cleaned_comment   \n",
      "0        Yeah, I get that argument. At this point, I'd ...                  \\\n",
      "1        The blazers and Mavericks (The wests 5 and 6 s...                   \n",
      "2                                  They're favored to win.                   \n",
      "3                               deadass don't kill my buzz                   \n",
      "4        Yep can confirm I saw the tool they use for th...                   \n",
      "...                                                    ...             ...   \n",
      "1010821  No one is calling this an engineered pathogen,...               n   \n",
      "1010822  In a move typical of their recent do-nothing a...                   \n",
      "1010823  Screw the Disabled--I've got to get to Church ...                   \n",
      "1010824  I've always been unsettled by that. I hear a l...                   \n",
      "1010825  Why do the people who make our laws seem unabl...                   \n",
      "\n",
      "         has_emoji                                      abbreviations  \n",
      "0            False                                           [nc, nh]  \n",
      "1            False  [know, west, team, play, against, west, team, ...  \n",
      "2            False  [underdog, earlier, today, since, gronk, annou...  \n",
      "3            False    [meme, not, funny, none, new, york, nigga, one]  \n",
      "4            False                            [could, use, one, tool]  \n",
      "...            ...                                                ...  \n",
      "1010821      False  [sure, iran, korea, technology, create, pig, b...  \n",
      "1010822      False                       [whatever, not, vote, green]  \n",
      "1010823      False  [perhaps, atheist, conspiracy, make, christian...  \n",
      "1010824      False          [slav, got, own, country, called, kosovo]  \n",
      "1010825      False  [value, capitalism, good, money, imprisoning, ...  \n",
      "\n",
      "[1010826 rows x 9 columns]\n",
      "\n",
      "DataFrame with abbreviations:\n",
      "         label abbreviations\n",
      "0            0            nc\n",
      "1            0            nh\n",
      "2            0          know\n",
      "3            0          west\n",
      "4            0          team\n",
      "...        ...           ...\n",
      "5757602      1    capitalism\n",
      "5757603      1          good\n",
      "5757604      1         money\n",
      "5757605      1   imprisoning\n",
      "5757606      1        people\n",
      "\n",
      "[5757607 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df_a = pd.DataFrame(df)\n",
    "\n",
    "# Function to remove abbreviations from text and return them\n",
    "def extract_abbreviations(text):\n",
    "    abbreviations = re.findall(r'\\b[A-Za-z]{2,}\\b', text)\n",
    "    cleaned_text = re.sub(r'\\b[A-Za-z]{2,}\\b', '', text)\n",
    "    return cleaned_text.strip(), abbreviations\n",
    "\n",
    "# Apply the function to the \"cleaned_comment\" column\n",
    "df_a[\"cleaned_comment\"], df_a[\"abbreviations\"] = zip(*df_a[\"cleaned_comment\"].apply(extract_abbreviations))\n",
    "\n",
    "# Create a new DataFrame to store abbreviations\n",
    "abbreviations_df = df_a.explode(\"abbreviations\")[[\"label\", \"abbreviations\"]].reset_index(drop=True)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_a)\n",
    "print(\"\\nDataFrame with abbreviations:\")\n",
    "print(abbreviations_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ac04ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abbreviations\n",
       "not          189446\n",
       "like          56606\n",
       "would         52737\n",
       "no            43510\n",
       "yeah          41104\n",
       "              ...  \n",
       "fresnel           1\n",
       "athos             1\n",
       "monitize          1\n",
       "delagates         1\n",
       "aghaghagh         1\n",
       "Name: count, Length: 143773, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbreviations_df['abbreviations'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c677c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
